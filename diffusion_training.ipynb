{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diffusion Model Training & Testing\n",
    "This notebook allows you to interactively train and test various diffusion model implementations.\n",
    "\n",
    "Remember to choose your virtual environment kernel before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import transforms, datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "# Import Implementations\n",
    "from implementations import base_implementation as base\n",
    "from implementations import edm_style_preconditioning as edm\n",
    "from implementations import v_parametrization as vparam\n",
    "from implementations import min_snr_reweighting as snr\n",
    "from implementations import progressive_difficulty_curriculum as pd\n",
    "from implementations import adaptive_sampling as adap_s\n",
    "from implementations import stf_smoothing as stf\n",
    "\n",
    "print('torch:', torch.__version__)\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('device ->', DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "seed_everything()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders(batch_size=128, img_size=32, num_workers=4, training_subset_size=None):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(img_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)), # map to [-1, 1] for CIFAR10\n",
    "    ])\n",
    "    train_ds = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "    test_ds = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "    if training_subset_size:\n",
    "        indices = list(range(training_subset_size))\n",
    "        train_ds = Subset(train_ds, indices)\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "    test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "    return train_loader, test_loader\n",
    "\n",
    "def show_image(path, figsize=(6,6)):\n",
    "    img = Image.open(path)\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "Set the flags below to `True` to enable specific implementations. You can also adjust hyperparameters here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Implementation Flags ---\n",
    "BASE = True\n",
    "EDM = False\n",
    "VPARAM = False\n",
    "SNR = False\n",
    "PD = False\n",
    "ADAP_S = False\n",
    "STF = False\n",
    "\n",
    "# --- Hyperparameters ---\n",
    "# Set LR_OVERRIDE to a specific float with scientific notation in a string (e.g. '1e-3') or None to run the default LR sweep\n",
    "LR_OVERRIDE: str = None\n",
    "\n",
    "TIMESTEPS = 1000\n",
    "EPOCHS = 1000\n",
    "BATCH_SIZE = 10_000\n",
    "AEOS_MEASURE_BS = 1000\n",
    "EMB_DIM_SIZE = 32\n",
    "CHECKPOINT_ROOT = \"\"\n",
    "\n",
    "# --- Prepare Checkpoints & LRs ---\n",
    "CHECKPOINT_FOLDER = []\n",
    "if os.path.isdir(CHECKPOINT_ROOT):\n",
    "    for item in os.listdir(CHECKPOINT_ROOT):\n",
    "        item_path = os.path.join(CHECKPOINT_ROOT, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            CHECKPOINT_FOLDER.append(item_path)\n",
    "\n",
    "def lookup_checkpoint(save_dir_name):\n",
    "    for folder in CHECKPOINT_FOLDER:\n",
    "        if save_dir_name in folder:\n",
    "            return os.path.join(folder, \"latest.pt\")\n",
    "    return None\n",
    "\n",
    "if LR_OVERRIDE is None:\n",
    "    LR_dict = {\n",
    "        1e-3: '_lr_1e-3',\n",
    "        5e-4: '_lr_5e-4',\n",
    "        1e-4: '_lr_1e-4',\n",
    "        5e-5: '_lr_5e-5',\n",
    "        1e-5: '_lr_1e-5',\n",
    "    }\n",
    "else:\n",
    "    LR_dict = {\n",
    "        float(LR_OVERRIDE): f'_lr_{LR_OVERRIDE}'\n",
    "    }\n",
    "print(\"Configuration Loaded.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution\n",
    "Run the cell below to start the training/testing loops based on the configuration above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- LOADING DATA ---\")\n",
    "train_loader, test_loader = get_dataloaders(batch_size=BATCH_SIZE, img_size=32, num_workers=2, training_subset_size=BATCH_SIZE)\n",
    "\n",
    "TOTAL_DATA = len(train_loader.dataset)\n",
    "print(f\"\\nTotal training data: {TOTAL_DATA} images\")\n",
    "\n",
    "print(\"--- RUNNING IMPLEMENTATIONS ---\")\n",
    "for LR, TEST_NAME_ADD_ON in LR_dict.items():\n",
    "    print(\"--- SETTINGS ---\")\n",
    "    print(f\"LR: {LR}\")\n",
    "    print(f\"Epochs: {EPOCHS}\")\n",
    "    print(f\"Batch size: {BATCH_SIZE}\")\n",
    "    print(f\"Timesteps: {TIMESTEPS}\")\n",
    "    print(f\"AEoS Measure Batch Size: {AEOS_MEASURE_BS}\")\n",
    "    print(f\"Embedding Dimension Size: {EMB_DIM_SIZE}\")\n",
    "\n",
    "    unet_setting = {\n",
    "        'in_ch':3, # 3 for CIFAR10\n",
    "        'base_ch':EMB_DIM_SIZE,\n",
    "        'time_emb_dim':EMB_DIM_SIZE,\n",
    "    }\n",
    "    schedule_settings = {\n",
    "        'timesteps':TIMESTEPS,\n",
    "        'device':DEVICE\n",
    "    }\n",
    "    train_settings = {\n",
    "        'train_loader':train_loader,\n",
    "        'device':DEVICE,\n",
    "        'epochs':EPOCHS,\n",
    "        'lr':LR,\n",
    "        'measure_bs': AEOS_MEASURE_BS,\n",
    "    }\n",
    "\n",
    "    # --- BASE ---\n",
    "    if BASE:\n",
    "        print(\"Running BASE Implementation\")\n",
    "        seed_everything()\n",
    "        model = base.UNet(**unet_setting)\n",
    "        schedule = base.DiffusionSchedule(**schedule_settings)\n",
    "        save_dir = './test_base' + TEST_NAME_ADD_ON\n",
    "        checkpoint = lookup_checkpoint(save_dir[2:])\n",
    "        print(f'Model parameters: {sum(p.numel() for p in model.parameters())/1e6:.2f}M')\n",
    "        base.train_ddim(\n",
    "            model=model,\n",
    "            schedule=schedule,\n",
    "            save_dir=save_dir,\n",
    "            checkpoint=checkpoint,\n",
    "            **train_settings\n",
    "        )\n",
    "\n",
    "    # --- EDM ---\n",
    "    if EDM:\n",
    "        print(\"Running EDM Implementation\")\n",
    "        seed_everything()\n",
    "        model = edm.UNet(**unet_setting)\n",
    "        save_dir = './test_edm_preconditioning' + TEST_NAME_ADD_ON\n",
    "        checkpoint = lookup_checkpoint(save_dir[2:])\n",
    "        print(f'Model parameters: {sum(p.numel() for p in model.parameters())/1e6:.2f}M')\n",
    "        edm.edm_train_ddim(\n",
    "            model=model,\n",
    "            save_dir=save_dir,\n",
    "            checkpoint=checkpoint,\n",
    "            **train_settings\n",
    "        )\n",
    "\n",
    "    # --- VPARAM ---\n",
    "    if VPARAM:\n",
    "        print(\"Running VPARAM Implementation\")\n",
    "        seed_everything()\n",
    "        model = vparam.UNet(**unet_setting)\n",
    "        schedule = vparam.DiffusionSchedule(**schedule_settings)\n",
    "        save_dir = './test_v_parametrization' + TEST_NAME_ADD_ON\n",
    "        checkpoint = lookup_checkpoint(save_dir[2:])\n",
    "        print(f'Model parameters: {sum(p.numel() for p in model.parameters())/1e6:.2f}M')\n",
    "        vparam.v_param_train_ddim(\n",
    "            model=model,\n",
    "            schedule=schedule,\n",
    "            save_dir=save_dir,\n",
    "            checkpoint=checkpoint,\n",
    "            **train_settings\n",
    "        )\n",
    "\n",
    "    # --- SNR ---\n",
    "    if SNR:\n",
    "        print(\"Running SNR Implementation\")\n",
    "        seed_everything()\n",
    "        model = snr.UNet(**unet_setting)\n",
    "        schedule = snr.MinSNRDiffusionSchedule(**schedule_settings)\n",
    "        save_dir = './test_min_snr_reweighting' + TEST_NAME_ADD_ON\n",
    "        checkpoint = lookup_checkpoint(save_dir[2:])\n",
    "        print(f'Model parameters: {sum(p.numel() for p in model.parameters())/1e6:.2f}M')\n",
    "        snr.min_snr_train_ddim(\n",
    "            model=model,\n",
    "            schedule=schedule,\n",
    "            save_dir=save_dir,\n",
    "            checkpoint=checkpoint,\n",
    "            **train_settings\n",
    "        )\n",
    "\n",
    "    # --- PD ---\n",
    "    if PD:\n",
    "        print(\"Running PD Implementation\")\n",
    "        seed_everything()\n",
    "        model = pd.UNet(**unet_setting)\n",
    "        schedule = pd.DiffusionSchedule(**schedule_settings)\n",
    "        save_dir = './test_progressive_difficulty' + TEST_NAME_ADD_ON\n",
    "        checkpoint = lookup_checkpoint(save_dir[2:])\n",
    "        print(f'Model parameters: {sum(p.numel() for p in model.parameters())/1e6:.2f}M')\n",
    "        pd.progressive_train_ddim(\n",
    "            model=model,\n",
    "            schedule=schedule,\n",
    "            save_dir=save_dir,\n",
    "            checkpoint=checkpoint,\n",
    "            **train_settings\n",
    "        )\n",
    "\n",
    "    # --- ADAP_S ---\n",
    "    if ADAP_S:\n",
    "        print(\"Running ADAP_S Implementation\")\n",
    "        seed_everything()\n",
    "        model = adap_s.UNet(**unet_setting)\n",
    "        schedule = adap_s.DiffusionSchedule(**schedule_settings)\n",
    "        save_dir = './test_adaptive_sampling' + TEST_NAME_ADD_ON\n",
    "        checkpoint = lookup_checkpoint(save_dir[2:])\n",
    "        print(f'Model parameters: {sum(p.numel() for p in model.parameters())/1e6:.2f}M')\n",
    "        adap_s.adaptive_train_ddim(\n",
    "            model=model,\n",
    "            schedule=schedule,\n",
    "            save_dir=save_dir,\n",
    "            checkpoint=checkpoint,\n",
    "            **train_settings\n",
    "        )\n",
    "\n",
    "    # --- STF ---\n",
    "    if STF:\n",
    "        print(\"Running STF Implementation\")\n",
    "        seed_everything()\n",
    "        model = stf.UNet(**unet_setting)\n",
    "        schedule = stf.DiffusionSchedule(**schedule_settings)\n",
    "        save_dir = './test_stf_smoothing' + TEST_NAME_ADD_ON\n",
    "        checkpoint = lookup_checkpoint(save_dir[2:])\n",
    "        print(f'Model parameters: {sum(p.numel() for p in model.parameters())/1e6:.2f}M')\n",
    "        stf.stf_train_ddim(\n",
    "            model=model,\n",
    "            schedule=schedule,\n",
    "            save_dir=save_dir,\n",
    "            checkpoint=checkpoint,\n",
    "            **train_settings\n",
    "        )\n",
    "\n",
    "    print(f\"--- ALL IMPLEMENTATIONS FINISHED FOR LR = {LR} ----\")\n",
    "print(\"--- ALL IMPLEMENTATIONS FINISHED FOR ALL LR ----\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eos-diffusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
